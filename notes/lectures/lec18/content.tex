\lecture{18}
\title{Denotational Semantics}
\date{14 March 2016}
\maketitle

\section{What is Denotational Semantics?}

So far we have looked at
\begin{itemize}
\item
\emph{operational semantics} involving rules for state transitions,
\item
\emph{definitional semantics} involving translations from a source language to a target language,
where the target language is simpler or better understood, and
\item
\emph{axiomatic semantics} involving logical rules for deriving relations between preconditions
and postconditions.
\end{itemize}
Another approach, known as \emph{denotational semantics}, involves translations to mathematical objects.
The objects in question are generally functions or relations with well-defined extensional meaning in terms of sets.
The main challenge is getting a precise understanding of the sets over which these function and relations operate.

\section{Diagonalization}

For example, consider the $\lambda$-term $\lambda x.x$. 
This clearly represents the identity function that takes the
input object $x$ to itself. But what is its domain? A more interesting example is the function $\lam x{xx}$.
Let's say that the domain of this function is $D$. Then $x$ represents some element of $D$, since $x$ is an input to the function. But in the body, $x$ is applied to $x$, so $x$ must also represent some function $D\to E$.
For this to make sense, it must be possible to interpret every element of $D$ as an element of the function space $D\to E$. Thus there must be a function $f:D\to(D\to E)$ taking $x\in D$ to the function $f(x):D\to E$ that it represents.

It is conceivable that $f$ could actually be a bijection between $D$ and the function space $D \to
E$. However, this is impossible if $E$ contains more than one element. In fact, $f$ cannot even be onto. This
follows by a diagonalization argument.\footnote{Due to Georg Cantor (1845--1918), the inventor of set theory.} Let $e_0,e_1\in E$, $e_0\neq e_1$.
For any function $f:D\to(D\to E)$, we can define $d:D\to E$ by $d = \lam x{\ifthenelse{f\,x\,x=e_0}{e_1}{e_0}}$. Then for all $x$, $d\,x\neq f\,x\,x$, so $d\neq f\,x$ for any $x$.

This type of argument is called \emph{diagonalization} because for countable sets $D$, the function $d$ is constructed by arranging the values $f\,x\,y$ for $x,y\in D$ in a countable matrix and going down the diagonal, creating a function that is different from every $f\,x$ on at least one input (namely $x$).
\[
\begin{array}{r|cccc}
& 0 & 1 & 2 & \\ \hline
f_{0} & f_{0}\,0 & f_{0}\,1 & f_{0}\,2 & \ldots\\
f_{1} & f_{1}\,0 & f_{1}\,1 & f_{1}\,2 & \ldots\\
f_{2} & f_{2}\,0 & f_{2}\,1 & f_{2}\,2 & \ldots\\
\vdots & \vdots
\end{array}
\]

Thus for any function $f:D\to(D\to E)$, where $E$ contains more than one element, there always exists a function $d:D\to E$ that is not $f\,x$ for any $x\in D$. This says that the cardinality (size) of the set of functions $D\to E$ is strictly larger than the cardinality of $D$, no matter what the sets $D$ and $E$ are, as long as $E$ contains at least two elements.
 
\section{Denotational Semantics of \IMP}
\label{sec:denotationalIMP}

When defining denotational semantics, we will use the notation $\lam{x\in D}e$ to indicate that the domain of the function is the set $D$. This will ensure that we are precise in identifying the extension of functions.

This is not really a type declaration. Later, we will introduce types and write them as $\lam{x:\tau}e$.
The distinction is that types are pieces of language syntax, whereas sets are semantic objects.

The syntax of \IMP\ was
\begin{eqnarray*}
a &::=& n \bnf x \bnf a_0+a_1 \bnf \ldots\\
b &::=& "true" \bnf "false" \bnf \neg b \bnf b_0\wedge b_1 \bnf a_0=a_1 \bnf \ldots \\
c &::=& "skip" \bnf \assg xa \bnf \comp{c_0}{c_1} \bnf \ifthenelse b{c_1}{c_2} \bnf \whiledo bc
\end{eqnarray*}
The syntactic categories of $a,b,c$ are arithmetic expressions \AExp, Boolean expressions \BExp, and commands \Com, respectively.

Our denotational semantics will be defined in terms of _states_, which are functions $\Env = \Var \to \Z$. Our semantics will interpret arithmetic expressions as functions from states to integers, Boolean expressions as functions from states to Boolean values $\Two = \{\true,\false\}$, and commands as \emph{partial} functions from states to states.
\begin{align*}
\SB[A]{a}\ &\in\ \Env \to \integers &
\SB[B]{b}\ &\in\ \Env \to \Two &
\SB[C]{c}\ &\in\ \Env \pfun \Env
\end{align*}
(The notation $\to$ denotes \emph{total} functions, those that produce a value on all inputs in the domain; and $\pfun$ denotes \emph{partial} functions, those that may not produce a value on all inputs in the domain.)
Given an initial state as input, the partial function \SB[C]{c} produces the final state reached by applying the command if the program $c$ halts; however, there will be no such final state if $c$ does not halt (e.g., $\whiledo{"true"}{"skip"}$). Thus the function is partial.

Now we can define the denotational semantics of expressions by structural induction. This induction is a little more complicated since we are defining all three functions at once. However, it is still well-founded because we only use the function value on subexpressions in the definitions. For arithmetic expressions,
\begin{align*}
\SBA[A]{n}\sigma\ &\definedas\ n & 
\SBA[A]{x}\sigma\ &\definedas\ \sigma(x) &
\SBA[A]{a_{1}+a_{2}}\sigma\ &\definedas\ \SBA[A]{a_1}\sigma + \SBA[A]{a_2}\sigma\\
\SBA[B]{\TRUE} \sigma\ &\definedas\ \true &
\SBA[B]{\FALSE} \sigma\ &\definedas\ \false &
\SBA[B]{\neg b} \sigma\ &\definedas\ 
 \begin{cases}
	\true, & \text{if $\SBA[B]{b} \sigma = \false$,}\\
	\false, & \text{if $\SBA[B]{b} \sigma = \true$.} 
 \end{cases}
\end{align*}
%\begin{align*}
%\SBA[A]{n}\sigma\ &\definedas\ n\\
%\SBA[A]{x}\sigma\ &\definedas\ \sigma(x) \\
%\SBA[A]{a_{1}+a_{2}}\sigma\ &\definedas\ \SBA[A]{a_1}\sigma + \SBA[A]{a_2}\sigma\\
%\SBA[B]{\TRUE} \sigma\ &\definedas\ \true \\
%\SBA[B]{\FALSE} \sigma\ &\definedas\ \false \\
%\SBA[B]{\neg b} \sigma\ &\definedas\ 
% \begin{cases}
%	\true, & \text{if $\SBA[B]{b} \sigma = \false$,}\\
%	\false, & \text{if $\SBA[B]{b} \sigma = \true$.} 
% \end{cases}
%\end{align*}
Note that by a slight but convenient abuse, we are overloading the metasymbol $+$ in the definition of $\SB[A]{a_{1}+a_{2}}$. The $+$ on the left-hand side represents a syntactic object, namely a symbol in the language \IMP, whereas the $+$ on the right-hand side represents a semantic object, namely the addition operation in the integers. We can also streamline the definition of $\SB[B]{\neg b}$ using a semantic \textsl{if-then-else}:
\begin{align*}
\SBA[B]{\neg b}\sigma\ &\definedas\ \metaifthenelse{\SBA[B]{b}\sigma}{\false}{\true}.
\end{align*}

For a command $c$, given an initial state as input, the function $\SB[C]c$ should produce the final state reached by applying $c$, provided the computation halts. However, there will be no such final state if $c$ does not halt; for example, $\whiledo{"true"}{"skip"}$. This is why the function is partial. However, we can make it a total function by including a special element $\bot$ (called _bottom_) denoting nontermination. For any set $S$, let $S_{\bot} \definedas S \cup \{\bot\}$. Then we can regard $\SB[C]c$ as a total function $\SB[C]c \in \Env \to \Env_{\bot}$, where $\SBA[C]c\sigma=\tau$ if $c$ terminates in state $\tau$ on input state $\sigma$, and $\SBA[C]c\sigma=\bot$ if $c$ does not terminate on input state $\sigma$.

Using this notation, we can define
\(
\SBA[C]{\SKIP}\sigma &\definedas& \sigma\\
\SBA[C]{\assg xa} \sigma &\definedas& \rebind\sigma{\SB[A]{a}\sigma}x\\
\SBA[C]{\ifthenelse b{c_1}{c_2}} \sigma &\definedas&
  \begin{cases}
	\SBA[C]{c_1}\sigma, & \text{if $\SBA[B]{b}\sigma = \true$,}\\
	\SBA[C]{c_2}\sigma, & \text{if $\SBA[B]{b}\sigma = \false$} 
  \end{cases}\\
&=& \metaifthenelse{\SBA[B]{b}\sigma}{\SBA[C]{c_1}\sigma}{\SBA[C]{c_2}\sigma}\\
\SBA[C]{\comp{c_1}{c_2}} \sigma &\definedas&
  \begin{cases}
	\SB[C]{c_2}\left(\SBA[C]{c_1}\sigma\right), & \text{if $\SBA[C]{c_1}\sigma\neq\bot$,}\\
	\bot, & \text{if $\SBA[C]{c_1}\sigma = \bot$} 
  \end{cases}\\
&=& \metaifthenelse{\SBA[C]{c_1}\sigma=\bot}{\bot}{\SB[C]{c_2}\left(\SBA[C]{c_1}\sigma\right).}
\)
For the last case involving sequential composition $\comp{c_1}{c_2}$, another way of achieving this effect is by defining a _lifting_ operator $(\cdot)^\dagger : (D \to E_{\bot}) \to (D_{\bot} \to E_{\bot})$ on functions:
\(
f^\dagger &\definedas& \fn x.\metaifthenelse{x = \bot}{\bot}{f(x)}.
\)
With this notation, we have
\(
\SBA[C]{\comp{c_1}{c_2}} \sigma &\definedas& \SB[C]{c_2}^\dagger\left(\SBA[C]{c_1}\sigma\right)
\)
or equivalently,
\(
\SB[C]{\comp{c_1}{c_2}} &\definedas& \SB[C]{c_2}^\dagger\circ\SB[C]{c_1},
\)
where $\circ$ denotes functional composition $(f\circ g)(\sigma) \definedas f(g(\sigma))$.

We have one command left: $\whiledo bc$. This is equivalent to $\ifthenelse b{(\comp c{\whiledo bc)}}{\SKIP}$, so a first guess at a definition might be:
\begin{align}
\SBA[C]{\whiledo bc}\sigma\ &\definedas\ \metaifthenelse{\SBA[B]b\sigma}{\SBA[C]{\comp c{\whiledo bc}}\sigma}\sigma\label{eq:Wdef0}\\
&=\ \metaifthenelse{\SBA[B]{b}\sigma}{\SB[C]{\while bc}^\dagger(\SBA[C]c\sigma)}\sigma,\nonumber
\end{align}
but this is circular. However, we can take a fixed point in some domain.
Replacing $\SB[C]{\whiledo bc}$ by $W$, we obtain a fixed-point equation
\begin{align*}
W\,\sigma\ &=\ \metaifthenelse{\SBA[B]{b}\sigma}{W^\dagger(\SBA[C]c\sigma)}\sigma,
\end{align*}
or rather
\begin{align}
W\ &=\ \lam{\sigma\in\Env}{\metaifthenelse{\SBA[B]{b}\sigma}{W^\dagger(\SBA[C]c\sigma)}\sigma},\label{eq:Wdef1}
\end{align}
and we would like $\SB[C]{\whiledo bc}$ to be a solution of this equation. Let us define
\(
\mathcal{F} &\definedas&
\lam{w\in\Env\rightarrow\Env_\bot}{\lam{\sigma\in\Env}{\metaifthenelse{\SBA[B]{b}\sigma}{w^\dagger(\SBA[C]c\sigma)}\sigma}}.
\)
Then we would like $W = \mathcal{F}\,W$; that is, we are looking for a fixed point of $\mathcal{F}$. But how do we take fixed points without using the dreaded $Y$ combinator? Eventually we will have a function "fix" with $W = "fix"\,\mathcal{F}$, where $\mathcal{F} \in (\Env \rightarrow \Env_\bot) \rightarrow (\Env \rightarrow \Env_\bot)$. The solution will be to think of a "while" statement as the limit of a sequence of approximations. Intuitively, by running through the loop more and more times, we will get better and better approximations.

The first and least accurate approximation is the totally undefined function
\(
W_0 &\definedas& \lam{\sigma\in\Env}\bot.
\)
The next approximation is
\(
W_1 &\definedas& \mathcal F\,W_0\\
&=& \lam{\sigma\in\Env}{\metaifthenelse{\SBA[B]{b}\sigma}{W_0^\dagger(\SBA[C]c\sigma)}\sigma}\\
&=& \lam{\sigma\in\Env}{\metaifthenelse{\SBA[B]{b}\sigma}{\bot}\sigma}.
\)
This simulates one iteration of the loop. We could then simulate two iterations by:
\(
W_2 &\definedas& \mathcal F\,W_1\ \ =\ \ \lam{\sigma\in\Env}{\metaifthenelse{\SBA[B]{b}\sigma}{W_1^\dagger(\SBA[C]c\sigma)}\sigma}.
\)
In general,
\(
W_{n+1} &\definedas& \mathcal F\,W_n\ \ =\ \ \lam{\sigma\in\Env}{\metaifthenelse{\SBA[B]{b}\sigma}{W_n^\dagger(\SBA[C]c\sigma)}\sigma}.
\)
Then denotation of the "while" statement should be the limit of this sequence. But how do we take limits in spaces of functions? To do this, we need some
structure on the space of functions. We will define an ordering $\sqsubseteq$ on
these functions such that $W_0 \sqsubseteq W_1 \sqsubseteq W_2 \sqsubseteq \cdots$, then find the least upper bound of this sequence. This will be the least solution of the equation \eqref{eq:Wdef1}.

In order to show that the least fixed point of $\mathcal F$ exists, we will apply the Knaster--Tarski theorem.  However, we only proved the Knaster--Tarski theorem for the partial order of subsets of some universal set ordered by set inclusion $\subseteq$.  We need to extend it to the more general case of chain-complete partial orders (CPOs).  To apply this theorem, we must know that the function space $\Env\to\Env_\bot$ is a CPO and that $\mathcal F$ is a continuous map on this space.

\section{Binary Relation Semantics}

An alternative but equivalent approach to the denotational semantics of \IMP\ is to interpret commands as binary relations, or sets of ordered pairs:
\begin{align*}
\SB{c}\ &\subseteq\ \Env\times\Env.
\end{align*}
Every partial and total function is extensionally just a binary relation: a total function is a binary relation containing \emph{exactly} one pair with first component $\sigma$ for each $\sigma$ in the domain, and a partial function is a binary relation containing \emph{at most} one pair with first component $\sigma$ for each $\sigma$ in the domain.

In this view, an equivalent definition to the above would be
\begin{align}
\SB{\SKIP}\ &\definedas\ \set{(\sigma,\sigma)}{\sigma\in\Env}\nonumber\\
\SB{\assg xa}\ &\definedas\ \set{(\sigma,\rebind\sigma{\SB[A]{a}\sigma}x)}{\sigma\in\Env}\nonumber\\
\SB{\ifthenelse b{c_1}{c_2}}\ &\definedas\ (\SB{c_1}\cap\set{(\sigma,\tau)}{\SBA[B]{b}\sigma = \true})\cup(\SB{c_2}\cap\set{(\sigma,\tau)}{\SBA[B]{b}\sigma = \false})\label{eq:itedef}\\
\SB{\comp{c_1}{c_2}}\ &\definedas\ \SB{c_2}\circ\SB{c_1},\nonumber
\end{align}
where $\circ$ denotes relational composition $R\circ S \definedas \set{(\sigma,\tau)}{\exists\rho\ (\sigma,\rho)\in S\wedge (\rho,\tau)\in R}$. The definition of the conditional \eqref{eq:itedef} can be further simplified by defining a binary relation
\begin{align*}
\SB{b}\ &\definedas\ \set{(\sigma,\sigma)}{\SBA[B]{b}\sigma = \true}
\end{align*}
for Boolean expressions $b$; then \eqref{eq:itedef} becomes
\begin{align}
\SB{\ifthenelse b{c_1}{c_2}}\ &=\ (\SB{c_1}\circ\SB{b}) \cup (\SB{c_2}\circ\SB{\neg b}).\label{eq:ifdef}
\end{align}
In this way the binary relation semantics of the conditional is defined in terms of the simpler set-theoretic operations $\cup$ and $\circ$ on relations.

For the while loop, we can take the least fixed point of a continuous map on binary relations. We can use the set-theoretic version of the Knaster--Tarski theorem for this. Using \eqref{eq:ifdef} to rewrite \eqref{eq:Wdef0} in terms of binary relations, we obtain
\begin{align*}
W\ &=\ (W\circ\SB c\circ\SB{b}) \cup \SB{\neg b}.
\end{align*}
One can show that the $\subseteq$-least solution of this equation is
\begin{align*}
W\ &=\ \SB{\neg b}\circ(\SBA c\circ\SB{b})\star,
\end{align*}
where $R\star$ denotes the reflexive-transitive closure of the relation $R$:
\begin{align*}
R^0 &= \set{(\sigma,\sigma)}{\sigma\in\Env} &
R^{n+1} &= R\circ R^n &
R\star &= \bigcup_n R^n,
\end{align*}
so we can define
\begin{align*}
\SB{\whiledo bc}\ &\definedas\ \SB{\neg b}\circ(\SBA c\circ\SB{b})\star.
\end{align*}

One can show

\begin{theorem}
For all $\sigma,\tau\in\Env$, the following are equivalent:
\begin{enumerate}
\def\labelenumi{{\upshape(\roman{enumi})}}
\item
$\config c\sigma\stepsto_{\mathrm{c}}\tau$ in the big-step semantics of Lecture 6;
\item
$\SBA[C]c\sigma = \tau$ in the denotational semantics of \S\ref{sec:denotationalIMP};
\item
$(\sigma,\tau)\in\SB c$ in the binary relation semantics of this section.
\end{enumerate}
\end{theorem}
