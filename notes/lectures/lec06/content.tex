\lecture{6}
\title{Well-Founded Induction}
\date{10 February 2016}
\maketitle

Perhaps the single most important proof technique in the theory of programming languages is \emph{mathmatical induction}. In this lecture we will take a very general look at the subject and identify necessary and sufficient conditions under which the induction principle is valid. We will define \emph{induction on a well-founded relation}, illustrate the definition with several examples, and then take another look at our inference rules in this light.

\section {Free Variables Revisited}

Recall that some of the substitution rules mentioned the set of free variables $\FV e$ that occur in the expression $e$.
\[
\begin{array}{rcll}
\subst{(\lam y{e_0})}{e_1}x &=& \lam y{(\subst{e_0}{e_1}x)}, & \mbox{where $y\neq x$ and $y\notin\FV{e_1}$},\\[3pt]
\subst{(\lam y{e_0})}{e_1}x &=& \lam z{(\subst{\subst{e_0}zy}{e_1}x)}, & \mbox{where $z\neq x$, $z\notin\FV{e_0}$, and $z\notin\FV{e_1}$}.
\end{array}
\]

\noindent
Let us examine the definition of the free-variable function $\FVname:\{\text{$\lambda$-terms}\}\to\Var$.
\begin{align*}
\FV x &= \{x\} &
\FV{e_1\,e_2} &= \FV{e_1} \cup \FV{e_2} &
\FV{\lam xe} &= \FV e - \{x\}.
\end{align*}
Why does this definition uniquely determine the function \FVname? There are two issues here:
\begin{itemize}
\item
\emph{existence}: whether \nm{FV} is defined on all $\lambda$-terms;
\item
\emph{uniqueness}: whether the definition is unique.
\end{itemize}
Of relevance is the fact that there are three clauses in the definition of \FVname\ corresponding to the three clauses in the definition of $\lambda$-terms and that a $\lambda$-term can be formed in one and only one way by one of these three clauses. Note also that although the symbol \FVname\ occurs on the right-hand side in two of these three clauses, they are applied to proper (\emph{proper} = strictly smaller) subterms.

The idea underlying this definition is called \emph{structural induction}. This is an instance of a general induction principle called \emph{induction on a well-founded relation}.

\section {Well-Founded Relations}

A binary relation $\prec$ is said to be \emph{well-founded} if it has no infinite descending chains. An \emph{infinite descending chain} is an infinite sequence of elements $a_0,a_1,a_2,\ldots$ such that $a_{i+1} \prec a_i$ for all $i\geq 0$. Note that a well-founded relation cannot be reflexive.

Here are some examples of well-founded relations:
\begin{itemize}
\item the successor relation $\{(m,m+1)\mid m\in\naturals\}$ on $\naturals$;
\item the less-than relation $\lt$ on $\naturals$;
\item the element-of relation $\in$ on sets. The axiom of foundation (or axiom of regularity) of Zermelo--Fraenkel (ZF) set theory implies that $\in$ is well-founded. Among other things, this prevents a set from being a member of itself;
\item the proper subset relation $\subset$ on the set of finite subsets of $\naturals$.
\end{itemize}
The following are not well-founded relations:
\begin{itemize}
\item the predecessor relation $\{(m+1,m)\mid m\in\naturals\}$ on $\naturals$ ($0,1,2,\ldots$ is an infinite \emph{descending} chain!);
\item the greater-than relation $\gt$ on $\naturals$;
\item the less-than relation $\lt$ on $\mathbb{Z}$ ($0,-1,-2,\ldots$ is an infinite descending chain);
\item the less-than relation $\lt$ on the real interval $[0,1]$ ($1,\frac 12,\frac 13,\frac 14,\ldots$ is an infinite descending chain);
\item the proper subset relation $\subset$ on subsets of $\naturals$ ($\naturals,\naturals-\{0\},\naturals-\{0,1\},\ldots$ is an infinite descending chain).
\end{itemize}

\section{Well-Founded Induction}

Let $\prec$ be a well-founded binary relation on a set $A$. Abstractly, a \emph{property} is just a map $P:A\to\Two$, or equivalently, a subset $P\subseteq A$ (the set of all $a\in A$ for which $P(a)=\true$).

The principle of well-founded induction on the relation $\prec$ says that in order to prove that a property $P$ holds for all elements of $A$, it suffices to prove that $P$ holds of any $a\in A$ whenever $P$ holds for all $b\prec a$. In other words,
\begin{eqnarray}
\forall a\in A\ (\forall b\in A\ b\prec a\Imp P(b)) \Imp P(a) &\ \Imp\ & \forall a\in A\ P(a).\label{eqn:induction}
\end{eqnarray}
Expressed as a proof rule,
\begin{equation}
\frac{\forall a\in A\ (\forall b\in A\ b\prec a\Imp P(b)) \Imp P(a)}{\forall a\in A\ P(a)} .\label{eqn:induction2}
\end{equation}
The basis of the induction is when $a$ has no $\prec$-predecessors; in that case, the premise $\forall b\in A\ b\prec a\Imp P(b)$ is vacuously true.

For the well-founded relation $\{(m,m+1)\mid m\in\naturals\}$, \eqref{eqn:induction} and \eqref{eqn:induction2} reduce to the familiar notion of mathematical induction on $\naturals$: to prove $\forall n\ P(n)$, it suffices to prove that $P(0)$ and that $P(n+1)$ whenever $P(n)$.

For the well-founded relation $\lt$ on $\naturals$, \eqref{eqn:induction} and \eqref{eqn:induction2} reduce to \emph{strong} induction on $\naturals$: to prove $\forall n\ P(n)$, it suffices to prove that $P(n)$ whenever $P(0),P(1),\ldots,P(n-1)$. When $n = 0$, the induction hypothesis is vacuously true.

\subsection{Equivalence of Well-Foundedness and the Validity of Induction}

In fact, one can show that the induction principle \eqref{eqn:induction}--\eqref{eqn:induction2} is valid for a binary relation $\prec$ on $A$ if and only if $\prec$ is well-founded.

To show that well-foundedness implies the validity of the induction principle, suppose for a contradiction that the induction principle were not valid. Then there would exist a property $P$ for which the premise of \eqref{eqn:induction2} holds but not the conclusion. Thus $P(a_0)$ would false for some element $a_0\in A$. The premise of \eqref{eqn:induction2} is equivalent to
\[
\forall a\in A\ \neg P(a) \Imp \exists b\in A\ b\prec a\wedge \neg P(b);
\]
this implies that there exists $a_1\prec a_0$ such that $P(a_1)$ is false. But since $P(a_1)$ is false, for the same reason there exists $a_2\prec a_1$ such that $P(a_2)$ is false. Continuing in this fashion, using the axiom of dependent choice (a weak form of the axiom of choice), one can construct an infinite descending chain $a_0,a_1,a_2,\ldots$ for which $P(a_i)$ is false for all $i\geq 0$, so $\prec$ is not well-founded.

Conversely, suppose that there exists an infinite descending chain $a_0,a_1,a_2,\ldots$~. Then the property $P(a)$ that says ``$a\notin\{a_0,a_1,a_2,\ldots\}$'' violates \eqref{eqn:induction2}, since the premise of \eqref{eqn:induction2} holds but not the conclusion.

\section{Structural Induction}

Now let us define a well-founded relation on the set of all $\lambda$-terms. Define $e \lt e'$ if $e$ is a \emph{proper} subterm of $e'$. A $\lambda$-term $e$ is a \emph{proper} (or \emph{strict}) subterm of $e'$ if it is a subterm of $e'$ and if $e\neq e'$. If we think of $\lambda$-terms as finite labeled trees, then $e'$ is a tree that has $e$ as a subtree. Since these trees are finite, the relation is well-founded. Induction on this relation is called \emph{structural induction}.

We can now show that $\FV e$ exists and is uniquely defined for any $\lambda$-term $e$. In the grammar for $\lambda$-terms, for any $e$, exactly one case in the definition of \FVname\ applies to $e$, and all references in the definition of \FVname\ are to subterms, which are strictly smaller. The function \FVname\ exists and is uniquely defined for the base case of the smallest $\lambda$-terms $x\in\Var$. So $\FV e$ exists and is uniquely defined for any $\lambda$-term $e$ by induction on the well-founded subexpression relation.

We often have a set of expressions in a language built from a set of \emph{constructors} starting from a set of \emph{generators}. For example, in the case of $\lambda$-terms, the generators are the variables $x\in\Var$ and the constructors are the binary application operator $\cdot$ and the unary abstraction operators $\lambda x$. The set of expressions defined by the generators and constructors is the smallest set containing the generators and closed under the constructors.

If a function is defined on expressions in such a way that
\begin{itemize}
\item there is one clause in the definition for every generator or constructor pattern,
\item the right-hand sides refer to the value of the function only on proper subexpressions,
\end{itemize}
then the function is well-defined and unique.

\section{Inference Rules}

We defined small-step semantics using inference rules. These rules are another kind of inductive definition. To prove properties of them, we would like to use well-founded induction.

To do this, we can change our view and look at reduction as a binary relation. To say that $e \stepsone e'$ according to the small-step rules just means that the pair $(e,e')$ is a member of some reduction relation, which is a subset of $\Exp \times \Exp$. In fact, not only is it a relation, it is a partial function.

For example, one of the small-step rules for call-by-value $\lambda$-calculus is

\begin{equation}
\Rule{\phantom{e_1 \stepsone e'_1}}{(\lam xe)\,v \stepsone \subst evx}
\qquad
\Rule{e_1 \stepsone e'_1}{e_1\,e_2 \stepsone e'_1\,e_2}
\qquad
\Rule{e \stepsone e'}{ v\,e \stepsone v\,e'}
\label{eqn:cbvrules}
\end{equation}
Here $e_1,e_2,e_1'$ are _metavariables_. Expressions appearing above the line are called _premises_, and the expression below the line is called the _conclusion_. Sometimes one also sees an expression in parentheses to the right of the rule; this is called a \emph{side condition} and represents a restriction on when the rule can be applied.\footnote{Side conditions and premises should not be confused. The difference is that side conditions are not part of the relation that the rule is trying to define, whereas the premises are.}

A \emph{rule instance} is a substitution for all the metavariables that satisfies the side condition. For example, here is an instance of the rule \eqref{eqn:cbvrules}:
\[
\Rule
{ (\lam x x) (\lam z z) \stepsone (\lam z z) }
{ ((\lam x x) (\lam z z)) \Omega \stepsone (\lam z z) \Omega }
\]

With rules like \eqref{eqn:cbvrules}, we are usually trying to define some set or relation by induction. For example, the rule \eqref{eqn:cbvrules} is part of the inductive definition of the reduction relation $\stepsone$, which is a subset of $\Exp \times \Exp$. Such rules are typically of the form
\begin{equation}
\Rule
[(\phi)]
{X_1\ X_2\ \ldots\ X_n}
X ,
\label{eqn:examplerule2}
\end{equation}
where $\seq X1n$ specify elements that are already members of the set or relation being defined and $X$ represents a new element constructed from $\seq X1n$ that is to be added to the relation. The side condition $\phi$, which may or may not be present, is a condition on $\seq X1n$ and $X$ that must hold for the rule to be applicable.

Now suppose we have written down a set of rules in an attempt to define a set or relation $A$. How do we know whether $A$ is well-defined? If the rule \eqref{eqn:examplerule2} is in force, then surely we would like to have $X\in A$ whenever $\seq X1n\in A$ and the side condition, if any, holds; but there may be many sets $A$ for which this is true, so this is hardly a definition.

\section{Set Operators}

To see how the definition works, we can view inference rules as \emph{monotone set operators}. Suppose we have a rule $R$ of the form \eqref{eqn:examplerule2}.
%\begin{equation}
%\Rule{X_1\ X_2\ \ldots\ X_n}{X},\label{eqn:rule}
%\end{equation}
%Define a _rule operator_ $R$ on sets as follows. Given a set $B$, let
%\begin{eqnarray*}
%R(B) &\definedas& \{ X \mid \{X_1,X_2,\ldots,X_n\} \subseteq B \mbox{ and } \frac{X_1~X_2~\ldots~X_n}{X} \mbox{ is a rule instance}\}
%\end{eqnarray*}
%Then
%\begin{itemize}
%\item $R(B)$ is the set of members of $A$ that can be inferred from the members of set $B$;
%\item $R(\emptyset)$ is the set of members that can be inferred from nothing;
%\item $R(R(\emptyset))$ is the set of members that can be inferred from $R(\emptyset)$; the elements of $R(\emptyset)$ are in this set because they are inferred from the empty set, which is a subset of $R(\emptyset)$.
%\end{itemize}
%
%Next time we will use the operator $R$ to define $A$ precisely.
%
%Recall from last time that a \emph{rule instance} is of the form
Thus the $X$ and the $X_j$ in \eqref{eqn:examplerule2} represent members of some set $S$. We can view $R$ as a mapping on subsets of $S$. Given $B\subseteq S$, define
\begin{eqnarray*}
R(B) &\definedas& \set X{\{X_1,X_2,\ldots,X_n\}\subseteq B\text{ and } \displaystyle\frac{X_1\ X_2\ \ldots\ X_n}X\text{ is an instance of \eqref{eqn:examplerule2}}}.
\end{eqnarray*}
Then $R$ is a function mapping subsets of $S$ to subsets of $S$; that is, $R:\powerset S\to\powerset S$, where $\powerset S$ denotes the \emph{powerset} (set of all subsets) of $S$.

Now suppose we have a finite set of such rules $\seq R1m$. What set $A\subseteq S$ is defined by the rules? At the very least, we would like $A$ to satisfy the following two properties:
\begin{itemize}
\item
$A$ is \emph{$R$-closed}: $R_1(A)\cup\cdots\cup R_m(A)\subseteq A$. We would like this to hold because we would like every element that the rules say should be included in $A$ are actually included in $A$.
\item
$A$ is \emph{$R$-consistent}: $A\subseteq R_1(A)\cup\cdots\cup R_m(A)$. We would like this to hold because we would like every element of $A$ to be included in $A$ \emph{only} as a result of applying one of the rules.
\end{itemize}
These two properties together say that $A=R_1(A)\cup\cdots\cup R_n(A)$, or in other words, $A$ should be a \emph{fixed point} of the set map
$\lam A{R_1(A)\cup\cdots\cup R_n(A)}$. This leads to two natural questions:
\begin{itemize}
\item
Does this map actually have a fixed point?
\item
Is the fixed point unique? If not, which one should we take?
\end{itemize}

We will answer these questions next time.
